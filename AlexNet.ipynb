{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"AlexNet\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 228, 228, 3)       0         \n",
      "_________________________________________________________________\n",
      "Conv_1_96_11x11_4 (Conv2D)   (None, 55, 55, 96)        34944     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 55, 55, 96)        384       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 55, 55, 96)        0         \n",
      "_________________________________________________________________\n",
      "maxpool_1_3x3_2 (MaxPooling2 (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "Conv_2_256_5x5_1 (Conv2D)    (None, 27, 27, 256)       614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 27, 27, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 27, 27, 256)       0         \n",
      "_________________________________________________________________\n",
      "maxpool_2_3x3_2 (MaxPooling2 (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "Conv_3_384_3x3_1 (Conv2D)    (None, 13, 13, 384)       885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 13, 13, 384)       1536      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 13, 13, 384)       0         \n",
      "_________________________________________________________________\n",
      "Conv_4_384_3x3_1 (Conv2D)    (None, 13, 13, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 13, 13, 384)       1536      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 384)       0         \n",
      "_________________________________________________________________\n",
      "Conv_5_256_3x3_1 (Conv2D)    (None, 13, 13, 256)       884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 13, 13, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "maxpool_3_3x3_2 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              37752832  \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                40970     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 58,360,626\n",
      "Trainable params: 58,341,470\n",
      "Non-trainable params: 19,156\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/lst/datasets/cifar-10-images_train/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fa8379202e35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_weight_height\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     class_mode='categorical')\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m validation_generator = test_datagen.flow_from_directory(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0mfollow_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m             \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         )\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             dtype=dtype)\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras_preprocessing/image/directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/lst/datasets/cifar-10-images_train/'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "AlexNet Keras implementation\n",
    "\"\"\"\n",
    "\n",
    "# Import necessary libs\n",
    "import os\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPool2D, ZeroPadding2D, Dense, Dropout, \\\n",
    "    Activation, Flatten, BatchNormalization, Input\n",
    "from keras.regularizers import l2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "import math\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1\"\n",
    "\n",
    "\n",
    "\n",
    "def AlexNet(input_shape=(224, 224, 3), num_classes=10, l2_reg=0.0, weights=None):\n",
    "    \"\"\"\n",
    "    AlexNet model\n",
    "    :param input_shape: input shape\n",
    "    :param num_classes: the number of classes\n",
    "    :param l2_reg:\n",
    "    :param weights:\n",
    "    :return: model\n",
    "    \"\"\"\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # Layer 1\n",
    "    # In order to get the same size of the paper mentioned, add padding layer first\n",
    "    x = ZeroPadding2D(padding=(2, 2))(input_layer)\n",
    "    x = conv_block(x, filters=96, kernel_size=(11, 11),\n",
    "                   strides=(4, 4), padding=\"valid\", l2_reg=l2_reg, name='Conv_1_96_11x11_4')\n",
    "    x = MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding=\"valid\", name=\"maxpool_1_3x3_2\")(x)\n",
    "\n",
    "    # Layer 2\n",
    "    x = conv_block(x, filters=256, kernel_size=(5, 5),\n",
    "                   strides=(1, 1), padding=\"same\", l2_reg=l2_reg, name=\"Conv_2_256_5x5_1\")\n",
    "    x = MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding=\"valid\", name=\"maxpool_2_3x3_2\")(x)\n",
    "\n",
    "    # Layer 3\n",
    "    x = conv_block(x, filters=384, kernel_size=(3, 3),\n",
    "                   strides=(1, 1), padding=\"same\", l2_reg=l2_reg, name=\"Conv_3_384_3x3_1\")\n",
    "\n",
    "    # Layer 4\n",
    "    x = conv_block(x, filters=384, kernel_size=(3, 3),\n",
    "                   strides=(1, 1), padding=\"same\", l2_reg=l2_reg, name=\"Conv_4_384_3x3_1\")\n",
    "\n",
    "    # Layer 5\n",
    "    x = conv_block(x, filters=256, kernel_size=(3, 3),\n",
    "                   strides=(1, 1), padding=\"same\", l2_reg=l2_reg, name=\"Conv_5_256_3x3_1\")\n",
    "    x = MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding=\"valid\", name=\"maxpool_3_3x3_2\")(x)\n",
    "\n",
    "    # Layer 6\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(units=4096)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # Layer 7\n",
    "    x = Dense(units=4096)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # Layer 8\n",
    "    x = Dense(units=num_classes)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"softmax\")(x)\n",
    "\n",
    "    if weights is not None:\n",
    "        x.load_weights(weights)\n",
    "    model = Model(input_layer, x, name=\"AlexNet\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def conv_block(layer, filters, kernel_size=(3, 3), strides=(1, 1), padding='valid', l2_reg=0.0, name=None):\n",
    "    x = Conv2D(filters=filters,\n",
    "               kernel_size=kernel_size,\n",
    "               strides=strides,\n",
    "               padding=padding,\n",
    "               kernel_regularizer=l2(l2_reg),\n",
    "               kernel_initializer=\"he_normal\",\n",
    "               name=name)(layer)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "input_shape = (224, 224, 3)\n",
    "num_classes = 10\n",
    "\n",
    "alexnet = AlexNet(input_shape=input_shape, num_classes=num_classes)\n",
    "alexnet.summary()\n",
    "\n",
    "parallel_model = multi_gpu_model(alexnet, gpus=2)\n",
    "\n",
    "epochs = 200\n",
    "model_name = \"AlexNet-2\"\n",
    "train_dir = r'/home/zxt/data/227/7k/'\n",
    "test_dir = r'/home/zxt/datasets/cifar-10-images_test/'\n",
    "batch_size = 256\n",
    "target_weight_height = (224, 224)\n",
    "\n",
    "parallel_model.compile(loss=['categorical_crossentropy'],\n",
    "                       optimizer='adadelta',\n",
    "                       metrics=[\"accuracy\"])\n",
    "tensorboard = TensorBoard(log_dir=f'./logs/{model_name}', histogram_freq=0,\n",
    "                          write_graph=True, write_images=False)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=1)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=target_weight_height,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=target_weight_height,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "num_train_samples = train_generator.samples\n",
    "num_val_samples = validation_generator.samples\n",
    "\n",
    "history = parallel_model.fit_generator(train_generator,\n",
    "                                       validation_data=validation_generator,\n",
    "                                       steps_per_epoch=math.ceil(num_train_samples / batch_size),\n",
    "                                       validation_steps=math.ceil(num_val_samples / batch_size),\n",
    "                                       epochs=epochs,\n",
    "                                       callbacks=[tensorboard, early_stopping],\n",
    "                                       )\n",
    "\n",
    "parallel_model.save(f\"{model_name}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
